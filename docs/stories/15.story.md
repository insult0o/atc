# Story 15: Frontend-Backend Integration

## Overview
Complete the integration between all frontend components and backend services, implementing state management, API client utilities, error handling, and ensuring seamless data flow throughout the application. This story connects all the pieces to create a fully functional PDF Intelligence Platform.

## User Story
As a developer, I want to seamlessly connect UI components to backend services, so that the platform functions as a cohesive system with excellent user experience.

## Acceptance Criteria
1. API client utilities created for all backend endpoints
2. State management implemented with Zustand/Redux
3. Error boundaries and error handling throughout UI
4. Loading and error states for all async operations
5. Optimistic UI updates for better responsiveness
6. Request caching strategy implemented
7. File upload handling with progress tracking
8. Export download management with proper UX

## Tasks / Subtasks

### Task 1: API Client Setup (AC: 1)
**Reference: [Source: architecture.md#api-client]**
- Create axios instance with interceptors
- Implement request/response handlers
- Add authentication headers
- Configure timeout and retry logic
- Create typed API methods
- **File Location**: `lib/api/client.ts`
- **Unit Tests**: API calls, error handling

### Task 2: State Management Implementation (AC: 2)
**Reference: [Source: architecture.md#state-management]**
- Set up Zustand stores
- Create document store
- Implement processing state store
- Add zone management store
- Create export state store
- **File Location**: `lib/stores/`
- **Unit Tests**: State updates, actions

### Task 3: Component API Integration (AC: 1, 2, 4)
**Reference: [Source: architecture.md#component-integration]**
- Connect DocumentUploadAndViewer to API
- Wire DualPaneViewer to state
- Integrate ZoneManager with backend
- Connect export components
- Update confidence controls
- **File Location**: `app/components/`
- **Unit Tests**: Component integration

### Task 4: Error Handling System (AC: 3, 4)
**Reference: [Source: architecture.md#error-handling]**
- Implement error boundaries
- Create error display components
- Add toast notifications
- Implement retry mechanisms
- Create fallback UI states
- **File Location**: `lib/errors/`
- **Unit Tests**: Error scenarios

### Task 5: Loading States and Optimistic Updates (AC: 4, 5)
**Reference: [Source: architecture.md#ui-states]**
- Add loading skeletons
- Implement progress indicators
- Create optimistic UI updates
- Add transition animations
- Implement state persistence
- **File Location**: `lib/ui/loading/`
- **Unit Tests**: State transitions

### Task 6: Request Caching with React Query (AC: 6)
**Reference: [Source: architecture.md#caching-strategy]**
- Set up React Query
- Configure cache invalidation
- Implement prefetching
- Add background refetching
- Create cache persistence
- **File Location**: `lib/query/`
- **Unit Tests**: Cache behavior

### Task 7: File Upload Integration (AC: 7)
**Reference: [Source: architecture.md#file-upload]**
- Implement chunked upload
- Add progress tracking
- Create upload queue
- Handle upload errors
- Implement resume capability
- **File Location**: `lib/upload/`
- **Unit Tests**: Upload scenarios

### Task 8: Export Download Management (AC: 8)
**Reference: [Source: architecture.md#export-download]**
- Create download manager
- Implement progress tracking
- Add download queue
- Handle large file downloads
- Create download history
- **File Location**: `lib/download/`
- **Unit Tests**: Download handling

## Dev Notes

### API Client Implementation [Source: architecture.md#api-client]
```typescript
import axios, { AxiosInstance, AxiosRequestConfig } from 'axios';
import { toast } from 'sonner';

class APIClient {
  private client: AxiosInstance;
  
  constructor() {
    this.client = axios.create({
      baseURL: process.env.NEXT_PUBLIC_API_URL || 'http://localhost:8000/api/v1',
      timeout: 30000,
      headers: {
        'Content-Type': 'application/json',
      },
    });
    
    this.setupInterceptors();
  }
  
  private setupInterceptors() {
    // Request interceptor
    this.client.interceptors.request.use(
      (config) => {
        // Add auth token if available
        const token = localStorage.getItem('auth_token');
        if (token) {
          config.headers.Authorization = `Bearer ${token}`;
        }
        
        // Add request ID
        config.headers['X-Request-ID'] = generateRequestId();
        
        return config;
      },
      (error) => Promise.reject(error)
    );
    
    // Response interceptor
    this.client.interceptors.response.use(
      (response) => response,
      async (error) => {
        const originalRequest = error.config;
        
        // Retry logic for network errors
        if (!error.response && !originalRequest._retry) {
          originalRequest._retry = true;
          return this.client(originalRequest);
        }
        
        // Handle specific error codes
        if (error.response?.status === 401) {
          // Handle unauthorized
          window.location.href = '/login';
        }
        
        return Promise.reject(error);
      }
    );
  }
  
  // Document endpoints
  async uploadDocument(file: File, onProgress?: (progress: number) => void) {
    const formData = new FormData();
    formData.append('file', file);
    
    return this.client.post('/documents/upload', formData, {
      headers: { 'Content-Type': 'multipart/form-data' },
      onUploadProgress: (progressEvent) => {
        if (onProgress && progressEvent.total) {
          const progress = (progressEvent.loaded / progressEvent.total) * 100;
          onProgress(progress);
        }
      },
    });
  }
  
  async getDocument(documentId: string) {
    return this.client.get(`/documents/${documentId}`);
  }
  
  async startProcessing(documentId: string, options: ProcessingOptions) {
    return this.client.post(`/process/${documentId}`, options);
  }
  
  async getProcessingStatus(documentId: string) {
    return this.client.get(`/process/${documentId}/status`);
  }
  
  // Zone endpoints
  async updateZone(documentId: string, zoneId: string, data: ZoneUpdate) {
    return this.client.patch(`/process/${documentId}/zones/${zoneId}`, data);
  }
  
  // Export endpoints
  async startExport(documentId: string, options: ExportOptions) {
    return this.client.post(`/export/${documentId}`, options);
  }
  
  async downloadExport(exportId: string) {
    return this.client.get(`/export/${exportId}/download`, {
      responseType: 'blob',
    });
  }
}

export const apiClient = new APIClient();
```

### Zustand State Management [Source: architecture.md#state-management]
```typescript
import { create } from 'zustand';
import { devtools, persist } from 'zustand/middleware';
import { immer } from 'zustand/middleware/immer';

interface DocumentState {
  documents: Document[];
  currentDocument: Document | null;
  isLoading: boolean;
  error: string | null;
  
  // Actions
  setDocuments: (documents: Document[]) => void;
  setCurrentDocument: (document: Document | null) => void;
  updateDocument: (id: string, updates: Partial<Document>) => void;
  addDocument: (document: Document) => void;
  removeDocument: (id: string) => void;
  setLoading: (loading: boolean) => void;
  setError: (error: string | null) => void;
}

export const useDocumentStore = create<DocumentState>()(
  devtools(
    persist(
      immer((set) => ({
        documents: [],
        currentDocument: null,
        isLoading: false,
        error: null,
        
        setDocuments: (documents) => set((state) => {
          state.documents = documents;
        }),
        
        setCurrentDocument: (document) => set((state) => {
          state.currentDocument = document;
        }),
        
        updateDocument: (id, updates) => set((state) => {
          const index = state.documents.findIndex(d => d.id === id);
          if (index !== -1) {
            state.documents[index] = { ...state.documents[index], ...updates };
          }
          if (state.currentDocument?.id === id) {
            state.currentDocument = { ...state.currentDocument, ...updates };
          }
        }),
        
        addDocument: (document) => set((state) => {
          state.documents.push(document);
        }),
        
        removeDocument: (id) => set((state) => {
          state.documents = state.documents.filter(d => d.id !== id);
          if (state.currentDocument?.id === id) {
            state.currentDocument = null;
          }
        }),
        
        setLoading: (loading) => set((state) => {
          state.isLoading = loading;
        }),
        
        setError: (error) => set((state) => {
          state.error = error;
        }),
      })),
      {
        name: 'document-store',
      }
    )
  )
);

// Processing State Store
interface ProcessingState {
  jobs: Map<string, ProcessingJob>;
  activeJobs: string[];
  
  // Actions
  addJob: (job: ProcessingJob) => void;
  updateJob: (jobId: string, updates: Partial<ProcessingJob>) => void;
  removeJob: (jobId: string) => void;
  setJobProgress: (jobId: string, progress: number) => void;
}

export const useProcessingStore = create<ProcessingState>()(
  devtools(
    immer((set) => ({
      jobs: new Map(),
      activeJobs: [],
      
      addJob: (job) => set((state) => {
        state.jobs.set(job.id, job);
        if (job.status === 'processing') {
          state.activeJobs.push(job.id);
        }
      }),
      
      updateJob: (jobId, updates) => set((state) => {
        const job = state.jobs.get(jobId);
        if (job) {
          state.jobs.set(jobId, { ...job, ...updates });
          
          // Update active jobs
          if (updates.status === 'completed' || updates.status === 'failed') {
            state.activeJobs = state.activeJobs.filter(id => id !== jobId);
          }
        }
      }),
      
      removeJob: (jobId) => set((state) => {
        state.jobs.delete(jobId);
        state.activeJobs = state.activeJobs.filter(id => id !== jobId);
      }),
      
      setJobProgress: (jobId, progress) => set((state) => {
        const job = state.jobs.get(jobId);
        if (job) {
          state.jobs.set(jobId, { ...job, progress });
        }
      }),
    }))
  )
);
```

### Component Integration Example [Source: architecture.md#component-integration]
```typescript
// DocumentUploadAndViewer integration
import { useDocumentStore } from '@/lib/stores/document-store';
import { useProcessingStore } from '@/lib/stores/processing-store';
import { apiClient } from '@/lib/api/client';
import { useMutation, useQuery } from '@tanstack/react-query';

export function DocumentUploadAndViewer() {
  const { currentDocument, setCurrentDocument, addDocument } = useDocumentStore();
  const { addJob } = useProcessingStore();
  const [uploadProgress, setUploadProgress] = useState(0);
  
  // File upload mutation
  const uploadMutation = useMutation({
    mutationFn: async (file: File) => {
      const response = await apiClient.uploadDocument(file, setUploadProgress);
      return response.data;
    },
    onSuccess: (data) => {
      addDocument(data);
      setCurrentDocument(data);
      toast.success('Document uploaded successfully');
    },
    onError: (error) => {
      toast.error('Failed to upload document');
      console.error(error);
    },
  });
  
  // Start processing mutation
  const processMutation = useMutation({
    mutationFn: async (options: ProcessingOptions) => {
      if (!currentDocument) throw new Error('No document selected');
      const response = await apiClient.startProcessing(currentDocument.id, options);
      return response.data;
    },
    onSuccess: (data) => {
      addJob(data);
      toast.success('Processing started');
    },
    onError: (error) => {
      toast.error('Failed to start processing');
    },
  });
  
  // Processing status query
  const { data: processingStatus } = useQuery({
    queryKey: ['processing-status', currentDocument?.id],
    queryFn: () => currentDocument ? apiClient.getProcessingStatus(currentDocument.id) : null,
    enabled: !!currentDocument,
    refetchInterval: (data) => {
      // Poll while processing
      return data?.status === 'processing' ? 1000 : false;
    },
  });
  
  return (
    <div className="document-upload-viewer">
      <UploadZone
        onUpload={(file) => uploadMutation.mutate(file)}
        isUploading={uploadMutation.isPending}
        uploadProgress={uploadProgress}
      />
      
      {currentDocument && (
        <DualPaneViewer
          document={currentDocument}
          processingStatus={processingStatus}
          onStartProcessing={(options) => processMutation.mutate(options)}
        />
      )}
    </div>
  );
}
```

### Error Boundary Implementation [Source: architecture.md#error-handling]
```typescript
import React, { Component, ErrorInfo, ReactNode } from 'react';
import { Button } from '@/components/ui/button';
import { AlertTriangle } from 'lucide-react';

interface Props {
  children: ReactNode;
  fallback?: ReactNode;
}

interface State {
  hasError: boolean;
  error: Error | null;
}

export class ErrorBoundary extends Component<Props, State> {
  public state: State = {
    hasError: false,
    error: null,
  };
  
  public static getDerivedStateFromError(error: Error): State {
    return { hasError: true, error };
  }
  
  public componentDidCatch(error: Error, errorInfo: ErrorInfo) {
    console.error('Uncaught error:', error, errorInfo);
    
    // Send to error tracking service
    if (process.env.NODE_ENV === 'production') {
      // logErrorToService(error, errorInfo);
    }
  }
  
  private handleReset = () => {
    this.setState({ hasError: false, error: null });
  };
  
  public render() {
    if (this.state.hasError) {
      if (this.props.fallback) {
        return this.props.fallback;
      }
      
      return (
        <div className="flex flex-col items-center justify-center min-h-[400px] p-8">
          <AlertTriangle className="w-12 h-12 text-red-500 mb-4" />
          <h2 className="text-xl font-semibold mb-2">Something went wrong</h2>
          <p className="text-gray-600 mb-4 text-center max-w-md">
            {this.state.error?.message || 'An unexpected error occurred'}
          </p>
          <Button onClick={this.handleReset} variant="outline">
            Try again
          </Button>
        </div>
      );
    }
    
    return this.props.children;
  }
}

// Global error handler hook
export function useErrorHandler() {
  return (error: Error, errorInfo?: { componentStack?: string }) => {
    console.error('Error caught by error handler:', error);
    
    // Show user-friendly error message
    toast.error(error.message || 'An unexpected error occurred', {
      action: {
        label: 'Retry',
        onClick: () => window.location.reload(),
      },
    });
    
    // Log to error tracking in production
    if (process.env.NODE_ENV === 'production') {
      // logErrorToService(error, errorInfo);
    }
  };
}
```

### File Upload with Progress [Source: architecture.md#file-upload]
```typescript
interface UploadManager {
  upload(file: File, options?: UploadOptions): UploadTask;
  pause(taskId: string): void;
  resume(taskId: string): void;
  cancel(taskId: string): void;
  getTask(taskId: string): UploadTask | undefined;
}

class ChunkedUploadManager implements UploadManager {
  private tasks = new Map<string, UploadTask>();
  private chunkSize = 5 * 1024 * 1024; // 5MB chunks
  
  upload(file: File, options?: UploadOptions): UploadTask {
    const taskId = generateId();
    const chunks = this.createChunks(file);
    
    const task: UploadTask = {
      id: taskId,
      file,
      status: 'pending',
      progress: 0,
      uploadedBytes: 0,
      totalBytes: file.size,
      chunks,
      currentChunk: 0,
    };
    
    this.tasks.set(taskId, task);
    this.startUpload(task);
    
    return task;
  }
  
  private createChunks(file: File): FileChunk[] {
    const chunks: FileChunk[] = [];
    let offset = 0;
    
    while (offset < file.size) {
      const end = Math.min(offset + this.chunkSize, file.size);
      chunks.push({
        index: chunks.length,
        start: offset,
        end,
        size: end - offset,
        uploaded: false,
      });
      offset = end;
    }
    
    return chunks;
  }
  
  private async startUpload(task: UploadTask) {
    task.status = 'uploading';
    
    try {
      // Initialize multipart upload
      const { uploadId } = await apiClient.initializeUpload({
        filename: task.file.name,
        fileSize: task.file.size,
        chunkCount: task.chunks.length,
      });
      
      task.uploadId = uploadId;
      
      // Upload chunks
      for (let i = task.currentChunk; i < task.chunks.length; i++) {
        if (task.status !== 'uploading') break;
        
        const chunk = task.chunks[i];
        const chunkData = task.file.slice(chunk.start, chunk.end);
        
        await this.uploadChunk(task, chunk, chunkData);
        
        task.currentChunk = i + 1;
        task.uploadedBytes += chunk.size;
        task.progress = (task.uploadedBytes / task.totalBytes) * 100;
        
        // Emit progress event
        this.emitProgress(task);
      }
      
      if (task.status === 'uploading' && task.currentChunk === task.chunks.length) {
        // Complete upload
        await apiClient.completeUpload(uploadId);
        task.status = 'completed';
      }
    } catch (error) {
      task.status = 'failed';
      task.error = error as Error;
    }
  }
  
  private async uploadChunk(task: UploadTask, chunk: FileChunk, data: Blob) {
    const formData = new FormData();
    formData.append('chunk', data);
    formData.append('uploadId', task.uploadId!);
    formData.append('chunkIndex', chunk.index.toString());
    
    await apiClient.uploadChunk(formData);
    chunk.uploaded = true;
  }
  
  pause(taskId: string) {
    const task = this.tasks.get(taskId);
    if (task && task.status === 'uploading') {
      task.status = 'paused';
    }
  }
  
  resume(taskId: string) {
    const task = this.tasks.get(taskId);
    if (task && task.status === 'paused') {
      this.startUpload(task);
    }
  }
  
  cancel(taskId: string) {
    const task = this.tasks.get(taskId);
    if (task) {
      task.status = 'cancelled';
      if (task.uploadId) {
        apiClient.cancelUpload(task.uploadId);
      }
      this.tasks.delete(taskId);
    }
  }
}
```

### React Query Setup [Source: architecture.md#react-query]
```typescript
import { QueryClient, QueryClientProvider } from '@tanstack/react-query';
import { ReactQueryDevtools } from '@tanstack/react-query-devtools';

const queryClient = new QueryClient({
  defaultOptions: {
    queries: {
      staleTime: 5 * 60 * 1000, // 5 minutes
      gcTime: 10 * 60 * 1000, // 10 minutes
      retry: (failureCount, error: any) => {
        if (error?.response?.status === 404) return false;
        return failureCount < 3;
      },
      refetchOnWindowFocus: false,
    },
    mutations: {
      retry: 1,
    },
  },
});

// Document queries
export const documentQueries = {
  all: () => ['documents'],
  lists: () => [...documentQueries.all(), 'list'],
  list: (filters: string) => [...documentQueries.lists(), { filters }],
  details: () => [...documentQueries.all(), 'detail'],
  detail: (id: string) => [...documentQueries.details(), id],
};

// Custom hooks
export function useDocument(documentId: string) {
  return useQuery({
    queryKey: documentQueries.detail(documentId),
    queryFn: () => apiClient.getDocument(documentId),
    enabled: !!documentId,
  });
}

export function useDocuments(filters?: DocumentFilters) {
  return useQuery({
    queryKey: documentQueries.list(JSON.stringify(filters)),
    queryFn: () => apiClient.getDocuments(filters),
  });
}

// Prefetching
export async function prefetchDocument(documentId: string) {
  await queryClient.prefetchQuery({
    queryKey: documentQueries.detail(documentId),
    queryFn: () => apiClient.getDocument(documentId),
  });
}

// Cache invalidation
export function invalidateDocument(documentId: string) {
  queryClient.invalidateQueries({
    queryKey: documentQueries.detail(documentId),
  });
}
```

### File Locations [Source: architecture.md#repository-structure]
- **API Client**: `lib/api/client.ts`
- **State Stores**: `lib/stores/`
- **Error Handling**: `lib/errors/`
- **Loading States**: `lib/ui/loading/`
- **Query Setup**: `lib/query/`
- **Upload Manager**: `lib/upload/`
- **Download Manager**: `lib/download/`
- **WebSocket Client**: `lib/websocket/`

### Testing Requirements [Source: architecture.md#testing]
- **Unit Tests**: API client methods, state updates
- **Integration Tests**: Component-API integration
- **E2E Tests**: Complete user flows
- **Error Tests**: Error boundary behavior
- **Performance Tests**: Cache efficiency

### Performance Targets [Source: architecture.md#performance]
- **API Response**: <200ms for cached data
- **State Updates**: <16ms for UI updates
- **File Upload**: >5MB/s throughput
- **Error Recovery**: <3s for retry
- **Cache Hit Rate**: >80% for repeated queries

## Project Structure Notes
This integration layer connects all frontend components with backend services through a well-structured API client, state management system, and error handling framework. React Query provides efficient data fetching and caching, while Zustand manages application state.

## Dependencies
- ✅ React 18+
- ✅ TypeScript
- ✅ Axios for HTTP
- ✅ Zustand for state
- ✅ React Query
- ✅ All frontend components
- ✅ Backend API (Stories 12-14)

## Status
Ready for Implementation

## Estimated Effort
- **API Client**: 1 day
- **State Management**: 1.5 days
- **Component Integration**: 2.5 days
- **Error Handling**: 1 day
- **Loading States**: 1 day
- **React Query Setup**: 1.5 days
- **File Upload**: 1.5 days
- **Download Manager**: 1 day
- **Testing**: 2 days
**Total**: 13 days

## Definition of Done
- [ ] API client configured and tested
- [ ] All stores implemented with actions
- [ ] Components connected to backend
- [ ] Error boundaries protecting all routes
- [ ] Loading states for all async operations
- [ ] React Query caching working properly
- [ ] File uploads with progress tracking
- [ ] Export downloads with proper UX
- [ ] All integration tests passing
- [ ] E2E tests for critical paths
- [ ] Performance targets met
- [ ] Documentation complete

---
*Story 15 - Epic 4: Backend Infrastructure and Integration*